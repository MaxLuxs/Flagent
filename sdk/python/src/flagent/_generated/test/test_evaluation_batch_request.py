# coding: utf-8

"""
    Flagent API

    Flagent is a feature flagging, A/B testing and dynamic configuration microservice. The base path for all the APIs is \"/api/v1\". ## Authentication Flagent supports multiple authentication methods (configured via environment variables): - **JWT Authentication**: Bearer token authentication - **Basic Authentication**: Username/password authentication - **Header Authentication**: Custom header-based authentication - **Cookie Authentication**: Cookie-based authentication Some endpoints (like `/health`, `/evaluation`) may be whitelisted and don't require authentication. ## Error Responses All error responses follow the same format: ```json {   \"message\": \"Error description\" } ``` Common HTTP status codes: - `200`: Success - `400`: Bad Request - invalid input parameters - `404`: Not Found - resource doesn't exist - `429`: Too Many Requests - rate limit exceeded - `500`: Internal Server Error - server error ## Rate Limiting Rate limiting is configured via environment variables: - `FLAGENT_RATELIMITER_PERFLAG_PERSECOND_CONSOLE_LOGGING`: Maximum evaluations per flag per second (default: 100) When rate limit is exceeded, the API returns `429 Too Many Requests` status code. ## Best Practices - Use batch evaluation (`/evaluation/batch`) when evaluating multiple flags for multiple entities - Use `enableDebug: true` only in development environments - Preload flags with `preload=true` parameter when fetching flags to reduce subsequent API calls - Use tags to organize and filter flags efficiently 

    The version of the OpenAPI document: 0.1.5
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from flagent._generated.models.evaluation_batch_request import EvaluationBatchRequest

class TestEvaluationBatchRequest(unittest.TestCase):
    """EvaluationBatchRequest unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> EvaluationBatchRequest:
        """Test EvaluationBatchRequest
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `EvaluationBatchRequest`
        """
        model = EvaluationBatchRequest()
        if include_optional:
            return EvaluationBatchRequest(
                entities = [
                    {"entityID":"user123","entityType":"user","entityContext":{"region":"US","tier":"premium"}}
                    ],
                enable_debug = True,
                flag_ids = [
                    56
                    ],
                flag_keys = [
                    ''
                    ],
                flag_tags = [
                    ''
                    ],
                flag_tags_operator = 'ANY'
            )
        else:
            return EvaluationBatchRequest(
                entities = [
                    {"entityID":"user123","entityType":"user","entityContext":{"region":"US","tier":"premium"}}
                    ],
        )
        """

    def testEvaluationBatchRequest(self):
        """Test EvaluationBatchRequest"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
